{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from overfit.trainers.overfit import OverfitTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from overfit.utils.img2vid import zigzag, display_video\n",
    "import torchvision.transforms.functional as FT\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import urllib\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "input_image = Image.open(\"dog.jpg\")\n",
    "input_tensor = FT.to_tensor(input_image)\n",
    "_, h, w = input_tensor.size()\n",
    "input_video = zigzag(input_tensor, h // 3, w // 3)\n",
    "# vid = display_video(input_video)\n",
    "# vid.save(\"dog.mp4\")\n",
    "print(len(input_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rgb(img):\n",
    "    return FT.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "input_video = [normalize_rgb(frame).unsqueeze(0) for frame in input_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcnet = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1).eval()\n",
    "tgtnet_trainer = OverfitTrainer()\n",
    "tgtnet_trainer.set(\n",
    "    pretrained_classifier=srcnet,\n",
    "    num_classes=1000,\n",
    "    confidence=0.1,\n",
    "    weight_decay=1,\n",
    "    max_lr=0.1,\n",
    "    momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5050\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'overfit' already exists. Creating a new version of this model...\n",
      "2022/09/15 19:47:55 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: overfit, version 6\n",
      "Created version '6' of model 'overfit'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "with mlflow.start_run() as run:\n",
    "    tgtnet_trainer.new_experiment()\n",
    "    tgtnet_trainer.test(input_video, [258] * len(input_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48a83ca3aee1feddb0dfc5a060f9f80ff0dd60294765f4f1c97838d8341a23c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
